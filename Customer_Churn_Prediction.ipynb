{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "eaOLk1rD2JaX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "FPT--Pdm0u4k"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import altair as alt\n",
        "%matplotlib inline\n",
        "pd.set_option(\"display.max_colwidth\", 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload Dataset"
      ],
      "metadata": {
        "id": "Z5jK9-wu2vTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./Churn_Modelling.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "fVTvEipy2M9b",
        "outputId": "c377eef5-002d-44b0-aa5e-e8a5181c8db1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
              "0          1    15634602  Hargrave          619    France  Female   42   \n",
              "1          2    15647311      Hill          608     Spain  Female   41   \n",
              "2          3    15619304      Onio          502    France  Female   42   \n",
              "3          4    15701354      Boni          699    France  Female   39   \n",
              "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
              "\n",
              "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0       2       0.00              1          1               1   \n",
              "1       1   83807.86              1          0               1   \n",
              "2       8  159660.80              3          1               0   \n",
              "3       1       0.00              2          0               0   \n",
              "4       2  125510.82              1          1               1   \n",
              "\n",
              "   EstimatedSalary  Exited  \n",
              "0        101348.88       1  \n",
              "1        112542.58       0  \n",
              "2        113931.57       1  \n",
              "3         93826.63       0  \n",
              "4         79084.10       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ba4fa30-747c-4f08-8a39-b85bdf77bb32\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ba4fa30-747c-4f08-8a39-b85bdf77bb32')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ba4fa30-747c-4f08-8a39-b85bdf77bb32 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ba4fa30-747c-4f08-8a39-b85bdf77bb32');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-af67cfc7-08d5-4fe0-a3b6-6ddebd6934b1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af67cfc7-08d5-4fe0-a3b6-6ddebd6934b1')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-af67cfc7-08d5-4fe0-a3b6-6ddebd6934b1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['RowNumber','CustomerId','Surname'], axis=1, inplace=True)\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd2cFAdu3WC_",
        "outputId": "0b49396e-4df8-4aae-b8b7-5eea23051097"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 11 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   CreditScore      10000 non-null  int64  \n",
            " 1   Geography        10000 non-null  object \n",
            " 2   Gender           10000 non-null  object \n",
            " 3   Age              10000 non-null  int64  \n",
            " 4   Tenure           10000 non-null  int64  \n",
            " 5   Balance          10000 non-null  float64\n",
            " 6   NumOfProducts    10000 non-null  int64  \n",
            " 7   HasCrCard        10000 non-null  int64  \n",
            " 8   IsActiveMember   10000 non-null  int64  \n",
            " 9   EstimatedSalary  10000 non-null  float64\n",
            " 10  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(7), object(2)\n",
            "memory usage: 859.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Test Split"
      ],
      "metadata": {
        "id": "EsQKmKHH4XOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.3, random_state=123)\n",
        "train_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruyKBw_14QaL",
        "outputId": "55123d5f-fb1b-4107-91c0-2aaa31b8104d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7000, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA"
      ],
      "metadata": {
        "id": "BrAe2Mbr4lI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()\n",
        "train_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "xTjcjCyv4hUt",
        "outputId": "a2e16485-e496-426f-b927-11426c71d30f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 7000 entries, 3144 to 3582\n",
            "Data columns (total 11 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   CreditScore      7000 non-null   int64  \n",
            " 1   Geography        7000 non-null   object \n",
            " 2   Gender           7000 non-null   object \n",
            " 3   Age              7000 non-null   int64  \n",
            " 4   Tenure           7000 non-null   int64  \n",
            " 5   Balance          7000 non-null   float64\n",
            " 6   NumOfProducts    7000 non-null   int64  \n",
            " 7   HasCrCard        7000 non-null   int64  \n",
            " 8   IsActiveMember   7000 non-null   int64  \n",
            " 9   EstimatedSalary  7000 non-null   float64\n",
            " 10  Exited           7000 non-null   int64  \n",
            "dtypes: float64(2), int64(7), object(2)\n",
            "memory usage: 656.2+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       CreditScore          Age       Tenure        Balance  NumOfProducts  \\\n",
              "count  7000.000000  7000.000000  7000.000000    7000.000000    7000.000000   \n",
              "mean    650.144571    38.942571     5.020143   76448.489407       1.534429   \n",
              "std      96.554892    10.612389     2.894639   62700.899244       0.582855   \n",
              "min     350.000000    18.000000     0.000000       0.000000       1.000000   \n",
              "25%     583.000000    32.000000     3.000000       0.000000       1.000000   \n",
              "50%     652.000000    37.000000     5.000000   96889.925000       1.000000   \n",
              "75%     717.000000    44.000000     8.000000  127838.535000       2.000000   \n",
              "max     850.000000    92.000000    10.000000  238387.560000       4.000000   \n",
              "\n",
              "         HasCrCard  IsActiveMember  EstimatedSalary       Exited  \n",
              "count  7000.000000     7000.000000      7000.000000  7000.000000  \n",
              "mean      0.705429        0.515286     99934.226306     0.204571  \n",
              "std       0.455882        0.499802     57555.469387     0.403417  \n",
              "min       0.000000        0.000000        11.580000     0.000000  \n",
              "25%       0.000000        0.000000     50743.832500     0.000000  \n",
              "50%       1.000000        1.000000     99729.890000     0.000000  \n",
              "75%       1.000000        1.000000    149458.040000     0.000000  \n",
              "max       1.000000        1.000000    199992.480000     1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ce5274d-a461-45cf-9f25-3f11b6b32c21\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7000.000000</td>\n",
              "      <td>7000.000000</td>\n",
              "      <td>7000.000000</td>\n",
              "      <td>7000.000000</td>\n",
              "      <td>7000.000000</td>\n",
              "      <td>7000.000000</td>\n",
              "      <td>7000.000000</td>\n",
              "      <td>7000.000000</td>\n",
              "      <td>7000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>650.144571</td>\n",
              "      <td>38.942571</td>\n",
              "      <td>5.020143</td>\n",
              "      <td>76448.489407</td>\n",
              "      <td>1.534429</td>\n",
              "      <td>0.705429</td>\n",
              "      <td>0.515286</td>\n",
              "      <td>99934.226306</td>\n",
              "      <td>0.204571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>96.554892</td>\n",
              "      <td>10.612389</td>\n",
              "      <td>2.894639</td>\n",
              "      <td>62700.899244</td>\n",
              "      <td>0.582855</td>\n",
              "      <td>0.455882</td>\n",
              "      <td>0.499802</td>\n",
              "      <td>57555.469387</td>\n",
              "      <td>0.403417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>350.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.580000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>583.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50743.832500</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>652.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>96889.925000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>99729.890000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>717.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>127838.535000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>149458.040000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>850.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>238387.560000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>199992.480000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ce5274d-a461-45cf-9f25-3f11b6b32c21')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ce5274d-a461-45cf-9f25-3f11b6b32c21 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ce5274d-a461-45cf-9f25-3f11b6b32c21');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-378dfb0c-5a02-4997-804b-e35e86df59cf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-378dfb0c-5a02-4997-804b-e35e86df59cf')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-378dfb0c-5a02-4997-804b-e35e86df59cf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"Exited\"].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcYtXxT34-de",
        "outputId": "2f7c7a6f-ea2f-4cf5-a8eb-6d2e14d09a10"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.795429\n",
              "1    0.204571\n",
              "Name: Exited, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, make_scorer, recall_score\n",
        "\n",
        "custom_scorer = make_scorer(f1_score, average=\"macro\")\n",
        "scoring_metric = custom_scorer"
      ],
      "metadata": {
        "id": "PrMjA2b-55dx"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seperating Class Label and Features"
      ],
      "metadata": {
        "id": "0TmhBIH16Cvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = (\n",
        "    train_df.drop(columns=[\"Exited\"]),\n",
        "    train_df[\"Exited\"],\n",
        ")\n",
        "X_test, y_test = (\n",
        "    test_df.drop(columns=[\"Exited\"]),\n",
        "    test_df[\"Exited\"],\n",
        ")"
      ],
      "metadata": {
        "id": "AaKFDMsz6NJU"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12,12))\n",
        "sns.heatmap(train_df.corr(), annot=True, ax=ax, cmap='BrBG').set(\n",
        "    title = 'Feature Correlation', xlabel = 'Columns', ylabel = 'Columns')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D6SByqSB6QMy",
        "outputId": "ba78491a-6af1-4712-90a6-424ef1216e10"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-63-17990fe91a1f>:2: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  sns.heatmap(train_df.corr(), annot=True, ax=ax, cmap='BrBG').set(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feat_corr = train_df.drop(columns='Exited').select_dtypes('number').apply(lambda x: x.corr(train_df.Exited))\n",
        "feat_corr = pd.DataFrame(feat_corr, columns=['correlation']).sort_values(['correlation'], ascending=False)\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.barplot(x=feat_corr['correlation'], y=feat_corr.index, palette=\"vlag\").set(\n",
        "title=\"Feature Correlation of Numeric Features\", xlabel=\"Feature Correlation\",\n",
        "ylabel=\"Feature Names\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "PI7Wzlon6TgG",
        "outputId": "fde43472-9e8b-4983-98b0-61f7cf97ce68"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing and transformations"
      ],
      "metadata": {
        "id": "AbI0GOw-7MJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_features = ['Gender', 'HasCrCard', 'IsActiveMember']\n",
        "categorical_features = ['Geography']\n",
        "numeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance','NumOfProducts', 'EstimatedSalary']\n",
        "target_column = ['Exited']\n",
        "\n",
        "preprocessor = make_column_transformer(\n",
        "    (StandardScaler(), numeric_features),\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\", sparse=False), categorical_features),\n",
        "    (OneHotEncoder(drop=\"if_binary\", dtype=int), binary_features),\n",
        "    (\"passthrough\", target_column)\n",
        ")\n",
        "\n",
        "train_data = preprocessor.fit_transform(train_df)\n",
        "categorical_feats = preprocessor.named_transformers_['onehotencoder-1'].get_feature_names_out(categorical_features).tolist()\n",
        "binary_feats = preprocessor.named_transformers_['onehotencoder-2'].get_feature_names_out(binary_features).tolist()\n",
        "\n",
        "feature_names = numeric_features + categorical_feats + binary_feats + target_column\n",
        "transformed_train_df = pd.DataFrame(train_data, columns=feature_names)\n",
        "\n",
        "# transform testing data\n",
        "test_data = preprocessor.transform(test_df)\n",
        "transformed_test_df = pd.DataFrame(test_data, columns=feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx2dCkeL6aPu",
        "outputId": "8da38795-9d9a-46a9-a7b0-f228eb9681f1"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_train_df.to_csv('./train.csv', index=False)\n",
        "transformed_test_df.to_csv('./test.csv', index=False)"
      ],
      "metadata": {
        "id": "k-Yod1jn7Nr_"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = transformed_train_df.drop(columns=[\"Exited\"]), transformed_train_df[\"Exited\"]\n",
        "X_test, y_test = transformed_test_df.drop(columns=[\"Exited\"]), transformed_test_df[\"Exited\"]"
      ],
      "metadata": {
        "id": "JRxG_PJQ7RXt"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define score comparison method"
      ],
      "metadata": {
        "id": "KYlJDON07mfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
        "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
        "\n",
        "    mean_scores = pd.DataFrame(scores).mean()\n",
        "    std_scores = pd.DataFrame(scores).std()\n",
        "    out_col = []\n",
        "\n",
        "    for i in range(len(mean_scores)):\n",
        "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
        "\n",
        "    return pd.Series(data=out_col, index=mean_scores.index)\n",
        "\n",
        "results = {}"
      ],
      "metadata": {
        "id": "iN2eJyWC7g4x"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the model"
      ],
      "metadata": {
        "id": "jxy987rQ8fM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "ratio = np.bincount(y_train)[0] / np.bincount(y_train)[1]\n",
        "ratio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1inMEBn175zH",
        "outputId": "9b711c3e-356f-4411-bff2-1db8fdfbb577"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.888268156424581"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm.sklearn import LGBMClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "models = {\n",
        "    \"random forest\": RandomForestClassifier(class_weight=\"balanced\", random_state=np.random.RandomState(123)),\n",
        "    \"xgboost\": XGBClassifier(scale_pos_weight=ratio, random_state=np.random.RandomState(123)),\n",
        "    \"lgbm\": LGBMClassifier(scale_pos_weight=ratio, random_state=np.random.RandomState(123)),\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    pipe = make_pipeline(model)\n",
        "    results[name] = mean_std_cross_val_scores(\n",
        "        pipe, X_train, y_train, return_train_score=True, scoring=scoring_metric\n",
        "    )\n",
        "\n",
        "pd.DataFrame(results).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "id": "VrCtYcGi8jfV",
        "outputId": "1212ee80-8b12-4e71-be26-f51f84c872ae"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000214 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000748 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        fit_time         score_time         test_score  \\\n",
              "random forest  0.576 (+/- 0.011)  0.028 (+/- 0.001)  0.737 (+/- 0.031)   \n",
              "xgboost        0.648 (+/- 0.521)  0.006 (+/- 0.000)  0.729 (+/- 0.018)   \n",
              "lgbm           0.090 (+/- 0.009)  0.010 (+/- 0.001)  0.739 (+/- 0.011)   \n",
              "\n",
              "                     train_score  \n",
              "random forest  1.000 (+/- 0.000)  \n",
              "xgboost        0.958 (+/- 0.005)  \n",
              "lgbm           0.884 (+/- 0.006)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bbbb4142-f058-427c-b16a-1890580d75d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>random forest</th>\n",
              "      <td>0.576 (+/- 0.011)</td>\n",
              "      <td>0.028 (+/- 0.001)</td>\n",
              "      <td>0.737 (+/- 0.031)</td>\n",
              "      <td>1.000 (+/- 0.000)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xgboost</th>\n",
              "      <td>0.648 (+/- 0.521)</td>\n",
              "      <td>0.006 (+/- 0.000)</td>\n",
              "      <td>0.729 (+/- 0.018)</td>\n",
              "      <td>0.958 (+/- 0.005)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lgbm</th>\n",
              "      <td>0.090 (+/- 0.009)</td>\n",
              "      <td>0.010 (+/- 0.001)</td>\n",
              "      <td>0.739 (+/- 0.011)</td>\n",
              "      <td>0.884 (+/- 0.006)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbbb4142-f058-427c-b16a-1890580d75d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bbbb4142-f058-427c-b16a-1890580d75d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bbbb4142-f058-427c-b16a-1890580d75d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1b5488ab-30d6-443c-a3e9-d9db48d85643\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b5488ab-30d6-443c-a3e9-d9db48d85643')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1b5488ab-30d6-443c-a3e9-d9db48d85643 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#among the 3 tree based models LGBM seems to be the best performing so we are going to proceed with that"
      ],
      "metadata": {
        "id": "qa7o89zo8wdz"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LGBM Hyperparameter Tunning"
      ],
      "metadata": {
        "id": "dOg2S5z79B6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_lgbm = {\n",
        "    \"lgbmclassifier__n_estimators\": randint(10, 100),\n",
        "    \"lgbmclassifier__max_depth\": randint(low=2, high=20),\n",
        "    \"lgbmclassifier__learning_rate\": [0.01, 0.1],\n",
        "    \"lgbmclassifier__subsample\": [0.5, 0.75, 1],\n",
        "}\n",
        "\n",
        "pipe_lgbm = make_pipeline(\n",
        "    models[\"lgbm\"],\n",
        ")"
      ],
      "metadata": {
        "id": "aDRoXmxx8-68"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_search_lgbm = RandomizedSearchCV(\n",
        "    pipe_lgbm,\n",
        "    param_grid_lgbm,\n",
        "    n_iter=50,\n",
        "    verbose=1,\n",
        "    n_jobs=1,\n",
        "    scoring=scoring_metric,\n",
        "    random_state=123,\n",
        "    return_train_score=True,\n",
        ")\n",
        "\n",
        "random_search_lgbm.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Hp1k_P_z9sIK",
        "outputId": "e3d9e1e5-87e7-4021-ffb7-8b77f941b3ae"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000763 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000246 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000258 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001081 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000814 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000234 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000244 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000239 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000214 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000260 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000260 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000261 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000241 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000243 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000242 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000246 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000250 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000249 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000241 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000241 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000242 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000248 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000262 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000243 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000257 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000256 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000248 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000249 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000255 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000261 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000245 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000232 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000216 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000244 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000205 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000315 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 857\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1146, number of negative: 4454\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204643 -> initscore=-1.357525\n",
            "[LightGBM] [Info] Start training from score -1.357525\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 1145, number of negative: 4455\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000244 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 860\n",
            "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204464 -> initscore=-1.358622\n",
            "[LightGBM] [Info] Start training from score -1.358622\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 1432, number of negative: 5568\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 859\n",
            "[LightGBM] [Info] Number of data points in the train set: 7000, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204571 -> initscore=-1.357964\n",
            "[LightGBM] [Info] Start training from score -1.357964\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(estimator=Pipeline(steps=[('lgbmclassifier',\n",
              "                                              LGBMClassifier(random_state=RandomState(MT19937) at 0x7EF8AA47B640,\n",
              "                                                             scale_pos_weight=3.888268156424581))]),\n",
              "                   n_iter=50, n_jobs=1,\n",
              "                   param_distributions={'lgbmclassifier__learning_rate': [0.01,\n",
              "                                                                          0.1],\n",
              "                                        'lgbmclassifier__max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7ef8a9ed1690>,\n",
              "                                        'lgbmclassifier__n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7ef8a9ed0310>,\n",
              "                                        'lgbmclassifier__subsample': [0.5, 0.75,\n",
              "                                                                      1]},\n",
              "                   random_state=123, return_train_score=True,\n",
              "                   scoring=make_scorer(f1_score, average=macro), verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=Pipeline(steps=[(&#x27;lgbmclassifier&#x27;,\n",
              "                                              LGBMClassifier(random_state=RandomState(MT19937) at 0x7EF8AA47B640,\n",
              "                                                             scale_pos_weight=3.888268156424581))]),\n",
              "                   n_iter=50, n_jobs=1,\n",
              "                   param_distributions={&#x27;lgbmclassifier__learning_rate&#x27;: [0.01,\n",
              "                                                                          0.1],\n",
              "                                        &#x27;lgbmclassifier__max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7ef8a9ed1690&gt;,\n",
              "                                        &#x27;lgbmclassifier__n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7ef8a9ed0310&gt;,\n",
              "                                        &#x27;lgbmclassifier__subsample&#x27;: [0.5, 0.75,\n",
              "                                                                      1]},\n",
              "                   random_state=123, return_train_score=True,\n",
              "                   scoring=make_scorer(f1_score, average=macro), verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=Pipeline(steps=[(&#x27;lgbmclassifier&#x27;,\n",
              "                                              LGBMClassifier(random_state=RandomState(MT19937) at 0x7EF8AA47B640,\n",
              "                                                             scale_pos_weight=3.888268156424581))]),\n",
              "                   n_iter=50, n_jobs=1,\n",
              "                   param_distributions={&#x27;lgbmclassifier__learning_rate&#x27;: [0.01,\n",
              "                                                                          0.1],\n",
              "                                        &#x27;lgbmclassifier__max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7ef8a9ed1690&gt;,\n",
              "                                        &#x27;lgbmclassifier__n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7ef8a9ed0310&gt;,\n",
              "                                        &#x27;lgbmclassifier__subsample&#x27;: [0.5, 0.75,\n",
              "                                                                      1]},\n",
              "                   random_state=123, return_train_score=True,\n",
              "                   scoring=make_scorer(f1_score, average=macro), verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;lgbmclassifier&#x27;,\n",
              "                 LGBMClassifier(random_state=RandomState(MT19937) at 0x7EF8AA47B640,\n",
              "                                scale_pos_weight=3.888268156424581))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=RandomState(MT19937) at 0x7EF8AA47B640,\n",
              "               scale_pos_weight=3.888268156424581)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best hyperparameter values: \", random_search_lgbm.best_params_)\n",
        "print(\"Best score: %0.3f\" % (random_search_lgbm.best_score_ * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boIXIbGp9veH",
        "outputId": "7a996810-5677-48d7-ef25-a423da8aacfa"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameter values:  {'lgbmclassifier__learning_rate': 0.01, 'lgbmclassifier__max_depth': 16, 'lgbmclassifier__n_estimators': 97, 'lgbmclassifier__subsample': 0.75}\n",
            "Best score: 75.490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result On the Test Set"
      ],
      "metadata": {
        "id": "J_m31H_E_Onv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "best_model = random_search_lgbm.best_estimator_\n",
        "print(\n",
        "    \"Grid Search best model validation score: %0.3f\" % (random_search_lgbm.best_score_)\n",
        ")\n",
        "\n",
        "predictions = best_model.predict(X_test)\n",
        "print(\n",
        "    \"Macro-average f1 score on the test set: %0.3f\"\n",
        "    % (f1_score(y_test, predictions, average=\"macro\"))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQaxdxGW-ZMK",
        "outputId": "0a887e19-234f-4566-eeed-f3cc8d95a3be"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid Search best model validation score: 0.755\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "Macro-average f1 score on the test set: 0.776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(\n",
        "    classification_report(\n",
        "        y_test, predictions, target_names=[\"Stayed\", \"Exited\"]\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVSi4ZXf_SNb",
        "outputId": "fdcaea5a-e302-4677-fee0-9070e47e01ad"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Stayed       0.90      0.93      0.91      2395\n",
            "      Exited       0.68      0.60      0.64       605\n",
            "\n",
            "    accuracy                           0.86      3000\n",
            "   macro avg       0.79      0.76      0.78      3000\n",
            "weighted avg       0.86      0.86      0.86      3000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}